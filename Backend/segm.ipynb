{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "from joblib import Parallel, delayed\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "image_dir = 'TB_Chest_Radiography_Database/Normal'\n",
    "output_dir = 'turberculoseN'\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "for imag_file in image_files:\n",
    "    imag_P = os.path.join(image_dir,imag_file)\n",
    "    img = cv2.imread(imag_P)\n",
    "\n",
    "    if img is None:\n",
    "        print(\"Erro\")\n",
    "        continue\n",
    "\n",
    "    img_Red = cv2.resize(img, (0, 0), fx=0.6, fy=0.6)\n",
    "    img_g = cv2.GaussianBlur(img_Red, (5, 5), 0)\n",
    "    gray = cv2.cvtColor(img_g, cv2.COLOR_BGR2GRAY)\n",
    "    thresh = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 11, 2)\n",
    "    kernel = np.ones((3, 3), np.uint8)\n",
    "    opening = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "\n",
    "    contours, hierarchy = cv2.findContours(opening, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    cv2.drawContours(img, contours, -1, (0, 255, 0), 2)\n",
    "\n",
    "    output_file = os.path.join(output_dir, f'resized_{imag_file}')\n",
    "    cv2.imwrite(output_file, opening)\n",
    "\n",
    "\n",
    "    # img_Red=cv2.resize(img,(0,0), fx=0.6, fy=0.6)\n",
    "    # #plt.imshow(img_Red)\n",
    "    # img_g= cv2.GaussianBlur(img_Red,(5,5),0)\n",
    "    # #plt.imshow(img_g)\n",
    "    # gray = cv2.cvtColor(img_g, cv2.COLOR_BGR2GRAY)\n",
    "    # ret, thresh = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
    "    # kernel = np.ones((3,3),np.uint8)\n",
    "    # erosion = cv2.erode(thresh,kernel,iterations = 1)\n",
    "    # dilation = cv2.dilate(erosion,kernel,iterations = 1)\n",
    "    # contours, hierarchy = cv2.findContours(dilation, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    # cv2.drawContours(img, contours, -1, (0,255,0), 2)\n",
    "    # output_file = os.path.join(output_dir, f'resized_{imag_file}')\n",
    "    # cv2.imwrite(output_file,dilation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "# Definindo diretórios\n",
    "p1 = 'turberculoseC'\n",
    "p2 = 'turberculoseN'\n",
    "train_dir = 'train'\n",
    "validation_dir = 'validation'\n",
    "\n",
    "# Criando as pastas train e validation\n",
    "if not os.path.exists(train_dir):\n",
    "    os.makedirs(train_dir)\n",
    "\n",
    "if not os.path.exists(validation_dir):\n",
    "    os.makedirs(validation_dir)\n",
    "\n",
    "# Definindo o tamanho do conjunto de treino e validação\n",
    "train_size = 0.7\n",
    "validation_size = 0.3\n",
    "\n",
    "# Mesclando as imagens das pastas p1 e p2 de forma aleatória\n",
    "images = []\n",
    "for img_name in os.listdir(p1):\n",
    "    images.append((os.path.join(p1, img_name), 1))\n",
    "for img_name in os.listdir(p2):\n",
    "    images.append((os.path.join(p2, img_name), 0))\n",
    "random.shuffle(images)\n",
    "\n",
    "# Copiando as imagens mescladas para as pastas train e validation\n",
    "for i, (image_path, label) in enumerate(images):\n",
    "    if i < len(images) * train_size:\n",
    "        dst_dir = os.path.join(train_dir, str(label))\n",
    "    else:\n",
    "        dst_dir = os.path.join(validation_dir, str(label))\n",
    "    if not os.path.exists(dst_dir):\n",
    "        os.makedirs(dst_dir)\n",
    "    shutil.copy(image_path, os.path.join(dst_dir, os.path.basename(image_path)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Definindo diretórios\n",
    "train_dir = 'train'\n",
    "validation_dir = 'validation'\n",
    "\n",
    "# Definindo número de classes e tamanho das imagens\n",
    "num_classes = 2\n",
    "img_width, img_height = 224, 224\n",
    "\n",
    "# Definindo o tamanho do batch de imagens a ser utilizado no treinamento\n",
    "batch_size = 30\n",
    "\n",
    "# Definindo geradores de imagens para treinamento e validação com aumento de dados\n",
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Criando geradores de imagens a partir dos diretórios\n",
    "train_generator = train_datagen.flow_from_directory(train_dir,\n",
    "                                                    target_size=(img_width, img_height),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(validation_dir,\n",
    "                                                       target_size=(img_width, img_height),\n",
    "                                                       batch_size=batch_size,\n",
    "                                                       class_mode='categorical')\n",
    "\n",
    "# Definindo a arquitetura da ResNet50 com pesos pré-treinados no ImageNet\n",
    "resnet_model = ResNet50(include_top=False, weights='imagenet',\n",
    "                        input_shape=(img_width, img_height, 3))\n",
    "\n",
    "# Congelando as camadas convolucionais da ResNet50\n",
    "for layer in resnet_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Adicionando camadas densas para classificação\n",
    "x = resnet_model.output\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "# Definindo o modelo final\n",
    "model = tf.keras.models.Model(inputs=resnet_model.input, outputs=output)\n",
    "\n",
    "# Compilando o modelo\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Treinando o modelo\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_generator.n // batch_size,\n",
    "                    epochs=20,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.n // batch_size)\n",
    "\n",
    "# Avaliando o modelo na validação\n",
    "scores = model.evaluate(validation_generator)\n",
    "print(f'Acurácia na validação: {scores[1]*100}%')\n",
    "\n",
    "# Salvando o modelo treinado\n",
    "model.save('tb_detection.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
